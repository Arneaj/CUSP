"""Module for the ground class."""
import datetime as dt
import glob
import os
import os.path
import re

import numpy as np
import pandas as pd

from .coordinates import (
    GEO_to_MAG,
    cart_to_polar,
    cart_to_sph,
    get_station_coords,
    sph_to_cart,
    sph_to_cart_vec,
    subsolar_angles,
)

AE_syn = ["A" + ("%02d" % i) for i in range(0, 48)]
KP_syn = ["K" + ("%02d" % i) for i in range(0, 48)]
grid_syn = ["G" + "%03d" % i for i in range(0, 1000)]


class ground:
    """Class for importing Gorgon ground field data.

    Stores key parameters and imports data from .csv files
    generated by the Gorgon MHD code.

    Args:
    ----
        path_to_data (str): Path to directory containing the simulation data
        (same as for gorgon_sim class).
        t0_UT (datetime, optional): UT datetime corresponding to t = 0
        in the simulation. Defaults to None.
        output (bool, optional): Choose whether to display list of variables and
        timesteps imported. Defaults to False.

    """

    def __init__(self, path_to_data, t0_UT=None, output=False):
        """Initialise the ground class."""
        self.t0_UT = t0_UT
        self.fdir = os.sep.join([path_to_data, "dB", os.sep])
        self.arr = {}
        self.timeseries = {}

        if self.fdir is not None:
            files = glob.glob(self.fdir + "/Output/" + r"*.csv")
            if len(files) == 0:
                print(
                    "No files found in directory: "
                    f'"{self.fdir}"'
                    f'"\nCreating empty class - use post-processing tools'
                    f"to generate ground data."
                )
                return
            file_names = [f.split(os.sep)[-1] for f in files]
            out = np.array([re.split("(?:_)|[.]", f) for f in file_names])
            self.times = np.unique(out[:, 1:-1])

            s = np.argsort([int(i) for i in self.times])
            self.times = self.times[s].astype(int)
            self.time = self.times[0]
            if t0_UT is not None:
                self.datetimes = np.array(
                    [self.t0_UT + dt.timedelta(seconds=int(t)) for t in self.times]
                )
                self.datetime = self.datetimes[0]

            filename = self.fdir + "/Stations/stns_" + str(self.time) + ".csv"
            self.import_stations(filename)

            if output:
                print("Ground Stations:", self.stations)
                print("Timesteps:", self.times)

    def import_stations(self, filename):
        """Import the names of all ground stations calculated in the simulation.

        Args:
        ----
            filename (str): The path to the file used to import the information.

        Raises:
        ------
            RuntimeWarning: Fails if no valid files are found.

        """
        # If file not found, exit function
        if not os.path.isfile(filename):
            if os.path.isfile(self.fdir + "/Stations/stns_sim.csv"):
                self.fixed_stns = True
                filename = self.fdir + "/Stations/stns_sim.csv"
            else:
                raise RuntimeWarning("Can't find file: " + filename)
                return
        else:
            self.fixed_stns = False

        self.stations = np.array(
            pd.read_csv(filename, delimiter=", ", engine="python")["stn"]
        )

    def import_timestep(self, t):
        """Import ionosphere arrays for a chosen timestep.

        Imports the .csv file for the specified timestep and saves a pandas dataframe
        containing the station data.

        Args:
        ----
            t (int): Chosen timestep for which to import variables.

        """
        self.time = self.times[t]
        if self.t0_UT is not None:
            self.datetime = self.datetimes[t]

        self.arr = pd.read_csv(
            self.fdir + "/Output/dB_" + str(self.times[t]) + ".csv",
            delimiter=", ",
            engine="python",
        )
        self.arr = self.arr.set_index("Station")
        if self.fixed_stns:
            stn_dat = pd.read_csv(
                self.fdir + "/Stations/stns_sim.csv", delimiter=", ", engine="python"
            )
        else:
            stn_dat = pd.read_csv(
                self.fdir + "/Stations/stns_" + str(self.times[t]) + ".csv",
                delimiter=", ",
                engine="python",
            )
        self.arr["x_sim"], self.arr["y_sim"], self.arr["z_sim"] = [
            np.array(stn_dat["x_sim"]) / 6.371e6,
            np.array(stn_dat["y_sim"]) / 6.371e6,
            np.array(stn_dat["z_sim"]) / 6.371e6,
        ]
        th, az = cart_to_polar(self.arr["x_sim"], self.arr["y_sim"], self.arr["z_sim"])
        self.arr["th"], self.arr["az"] = np.pi / 2 - th, az

    def timestep(self, time):
        """Return simulation timestep (indexed from 0) corresponding to a given time.

        Args:
        ----
            time (int): Simulation time in seconds.

        Raises:
        ------
            RuntimeWarning: Fails if there is no data for the given time.

        Returns:
        -------
            int: Timestep corresponding to the given time.

        """
        if not np.any(self.times == time):
            raise RuntimeWarning("Could not import timestep for time: " + str(time))
            return
        else:
            return np.where(self.times == time)[0][0]

    def import_timeseries(self, stations, starttime=None, endtime=None):
        """Import ionosphere arrays for a chosen timerange.

        Args:
        ----
            stations (list): List of stations for which to import variables.
            starttime (optional): Start time of the timerange to import.
            Defaults to None.
            endtime (optional): End time of the timerange to import. Defaults to None.

        """
        # Define chosen timerange
        t_init = self.time
        starttime = self.times[0] if starttime is None else starttime
        endtime = self.times[-1] if endtime is None else endtime
        times = self.times[self.timestep(starttime) : self.timestep(endtime) + 1]

        # Initialise dataframes for each chosen station
        stn_vars = [
            "th",
            "az",
            "Bx_m",
            "Bx_f",
            "Bx_h",
            "Bx_p",
            "By_m",
            "By_f",
            "By_h",
            "By_p",
            "Bz_m",
            "Bz_f",
            "Bz_h",
            "Bz_p",
        ]
        for stn in stations:
            dat = pd.DataFrame(index=times, columns=stn_vars)
            dat.index.name = "timestep"
            self.timeseries[stn] = dat

        # Load data for each timestep (if available)
        for time in times:
            self.import_timestep(self.timestep(time))
            for stn in stations:
                for var in stn_vars:
                    self.timeseries[stn][var][time] = self.arr[var][stn]

        # Store UT times (if applicable)
        if self.t0_UT is not None:
            for stn in stations:
                self.timeseries[stn].insert(
                    0,
                    "UT",
                    self.datetimes[
                        self.timestep(times[0]) : self.timestep(times[-1]) + 1
                    ],
                )

        self.time = t_init

        self.calc_vectors(stations)

    def write_timeseries(
        self, stations, folder, starttime=None, endtime=None, UT_mode=None
    ):
        """Write timeseries data to CSV files.

        Args:
        ----
            stations (list): List of station names to write data for.
            folder (str): Folder path to write CSV files to.
            starttime (optional): Start time of the data to write. If not specified,
            the start time of the data will be used.
            endtime (optional): End time of the data to write. If not specified, the end
            time of the data will be used.
            UT_mode (str, optional): UT mode to use for writing data. Valid options are
            "MAG", "GEO", or "both". If not specified, the default is to write data in
            the same UT mode as the input data.

        Raises:
        ------
            RuntimeError: If UT_mode is "MAG" or "both" and t0_UT is not defined.

        Returns:
        -------
            None

        """
        for stn in stations:
            if starttime is None:
                starttime = self.timeseries[stn].index[0]
            if endtime is None:
                endtime = self.timeseries[stn].index[-1]
            if UT_mode is None:
                self.timeseries[stn].loc[self.timeseries[stn].index >= starttime].loc[
                    self.timeseries[stn].index <= endtime
                ].to_csv(folder + "/output" + stn + ".csv", index_label="timestep")
            else:
                if self.t0_UT is None:
                    raise RuntimeError(
                        "No UT time defined, please specify t0_UT when "
                        "initialising ground class."
                    )
                elif UT_mode == "MAG":
                    df = self.timeseries[stn][
                        ["UT", "Bx_MAG", "By_MAG", "Bz_MAG"]
                    ].copy()
                    df.columns = ["UT", "Bn", "Be", "Bz"]
                    df = df.set_index("UT")
                    df.to_csv(folder + "/output" + stn + ".csv", index_label="UT")
                elif UT_mode == "GEO":
                    df = self.timeseries[stn][
                        ["UT", "Bx_GEO", "By_GEO", "Bz_GEO"]
                    ].copy()
                    df.columns = ["UT", "Bx", "By", "Bz"]
                    df = df.set_index("UT")
                    df.to_csv(folder + "/output" + stn + ".csv", index_label="UT")
                elif UT_mode == "both":
                    df = self.timeseries[stn][
                        [
                            "UT",
                            "Bx_MAG",
                            "By_MAG",
                            "Bz_MAG",
                            "Bx_GEO",
                            "By_GEO",
                            "Bz_GEO",
                        ]
                    ].copy()
                    df.columns = ["UT", "Bn", "Be", "Bz", "Bx", "By", "Bz"]
                    df = df.set_index("UT")
                    df.to_csv(folder + "/output" + stn + ".csv", index_label="UT")

    def read_timeseries(self, stations, folder):
        """Read timeseries data for a list of stations.

        Read timeseries data for a list of stations from a specified folder
        and stores it in a dictionary.

        Args:
        ----
            stations (list): A list of station names.
            folder (str): The path to the folder containing the timeseries data.

        Returns:
        -------
            None

        """
        for stn in stations:
            self.timeseries[stn] = pd.read_csv(folder + "/output" + stn + ".csv")
            self.timeseries[stn] = self.timeseries[stn].set_index("timestep")

    def elecproject(self, iono, stations, starttime=None, endtime=None):
        """Projects electric fields onto a set of ground-based magnetometer stations.

        Args:
        ----
            iono (IonoContainer): An instance of the IonoContainer class containing
            ionospheric data.
            stations (list): A list of station codes to project electric fields onto.
            starttime (optional): The start time of the projection. Defaults to None.
            endtime (optional): The end time of the projection. Defaults to None.

        Returns:
        -------
            None

        """
        # WARNING - will fail is self.t0_UT is None but coords='MAG'

        coords = "sim" if self.t0_UT is None else "MAG"
        if coords == "sim" or np.any(
            [stn in np.append(np.append(AE_syn, KP_syn), grid_syn) for stn in stations]
        ):
            timeseries_sim = iono.import_timerange(
                starttime, endtime, self.t0_UT, coords="sim"
            )
        if coords == "MAG":
            timeseries_MAG = iono.import_timerange(
                starttime, endtime, self.t0_UT, coords="MAG"
            )
        stn_vars = [
            "th",
            "az",
            "Bx_m",
            "Bx_f",
            "Bx_h",
            "Bx_p",
            "By_m",
            "By_f",
            "By_h",
            "By_p",
            "Bz_m",
            "Bz_f",
            "Bz_h",
            "Bz_p",
        ]

        from .elecproject import elecproject

        for stn in stations:
            ejet = elecproject(
                stn
            )  # unique class for each station, but same global time-series
            if coords == "sim" or stn in AE_syn or stn in KP_syn or stn in grid_syn:
                ejet.sample_region(timeseries_sim, sim_coords=True)
            else:
                ejet.sample_region(
                    timeseries_MAG, sim_coords=False
                )  # if applicable sample on MAG coord data arrays

            ejet.calc_ground_fields(
                Z=1e20 + 1e20j, t_window=1 * 60, conduct="pedersen", ignore_FAC=True
            )
            B_ped = 1e9 * ejet.B_ground[:, ::60].T
            ejet.calc_ground_fields(
                Z=1e20 + 1e20j, t_window=1 * 60, conduct="pedersen", ignore_FAC=False
            )
            B_FAC = 1e9 * ejet.B_ground[:, ::60].T - B_ped
            ejet.calc_ground_fields(
                Z=1e20 + 1e20j, t_window=1 * 60, conduct="hall", ignore_FAC=True
            )
            B_hall = 1e9 * ejet.B_ground[:, ::60].T

            self.times = ejet.mag_times[::60]
            if self.t0_UT is not None:
                self.datetimes = np.array(
                    [self.t0_UT + dt.timedelta(seconds=int(t)) for t in self.times]
                )

            if stn not in AE_syn and stn not in KP_syn and stn not in grid_syn:
                obs_th_GEO, obs_az_GEO = ejet.loc  # station GEO colatitude, longitude
                obs_lat_MAG, obs_az_MAG = GEO_to_MAG(
                    np.pi / 2 - obs_th_GEO, obs_az_GEO, np.array([self.t0_UT])
                )  # GEO to MAG
                obs_th_MAG = np.pi / 2 - obs_lat_MAG  # back to colatitude
                _, ss_az = subsolar_angles(
                    self.datetimes
                )  # angle between MAG and SM X-axes
                obs_th_SM, obs_az_SM = obs_th_MAG, obs_az_MAG - ss_az  # MAG to SM
                obs_x, obs_y, obs_z = sph_to_cart(
                    iono.r_P, obs_th_SM, obs_az_SM + np.pi
                )  # to cartesian, adding pi to azimuth for sim x,y directions
                _, clt, lon = cart_to_sph(
                    obs_x, obs_y, obs_z
                )  # back to spherical for iono and FAC
            else:
                clt, lon = get_station_coords(stn)

            dat = pd.DataFrame(index=self.times, columns=stn_vars)
            dat.index.name = "timestep"

            label = ["f", "h", "p"]
            for i, B in enumerate([B_FAC, B_hall, B_ped]):
                Bn, Be, Bz = B[:, 0], B[:, 1], B[:, 2]  # NEZ
                Br, Bth, Baz = -Bz, -Bn, Be  # NEZ -> SM spherical polar
                Bx, By, Bz = sph_to_cart_vec(
                    Br, Bth, Baz, clt, lon + np.pi
                )  # SM spherical polar -> SM cartesian (needs to change longitude given
                # change in axes)
                Bx, By, Bz = -Bx, -By, Bz  # SM cartesian -> sim cartesian
                dat["Bx_" + label[i]], dat["By_" + label[i]], dat["Bz_" + label[i]] = (
                    Bx,
                    By,
                    Bz,
                )
            dat["Bx_m"], dat["By_m"], dat["Bz_m"] = 0 * Bx, 0 * Bx, 0 * Bx
            dat["th"], dat["az"] = clt, lon

            self.timeseries[stn] = dat
            if self.t0_UT is not None:
                self.timeseries[stn].insert(0, "UT", self.datetimes)

        self.calc_vectors(stations)

    def calcdeltaB(self, sim, iono, stations, starttime=None, endtime=None):
        """Calculate the change in magnetic field at a set of stations.

        Args:
        ----
            sim (gorgon_sim): An instance of the gorgon_sim class containing simulation
            data.
            iono (IonoContainer): An instance of the IonoContainer class containing
            ionospheric data.
            stations (list): A list of station codes to calculate deltaB for.
            starttime (optional): The start time of the calculation. Defaults to None.
            endtime (optional): The end time of the calculation. Defaults to None.

        Returns:
        -------
            None

        """
        from .calcdeltaB import calcdeltaB

        starttime = sim.times[0] if starttime is None else starttime
        endtime = sim.times[-1] if endtime is None else endtime

        for stn in stations:
            station = [stn, get_station_coords(stn)[0], get_station_coords(stn)[1]]
            if stn in AE_syn or stn in KP_syn or stn in grid_syn:
                t0_UT = None
            else:
                t0_UT = self.t0_UT
            dat = calcdeltaB(
                sim, iono, starttime, endtime, station, t0_UT=t0_UT, extent=[20, 20, 20]
            )
            self.times = np.array(dat.index)
            if self.t0_UT is not None:
                self.datetimes = np.array(
                    [self.t0_UT + dt.timedelta(seconds=int(t)) for t in self.times]
                )
                if not t0_UT:
                    dat.insert(
                        0, "UT", self.datetimes
                    )  # Although defined already for geographic stations, it won't be
                    # for synthetic ones

            self.timeseries[stn] = dat

        self.calc_vectors(stations)

    def calc_vectors(self, stations):
        """Calculate vector components of magnetic field.

        Args:
        ----
            stations (list): A list of station codes to calculate vector components for.

        Returns:
        -------
            None

        """
        from .calcdeltaB import calc_B_vectors

        for stn in stations:
            dat = calc_B_vectors(
                self.timeseries[stn].copy(),
                [stn, get_station_coords(stn)[0], get_station_coords(stn)[1]],
            )
            (
                self.timeseries[stn]["Bx_MAG"],
                self.timeseries[stn]["By_MAG"],
                self.timeseries[stn]["Bz_MAG"],
            ) = (dat["B_nez"][:, 0], dat["B_nez"][:, 1], dat["B_nez"][:, 2])
            if self.t0_UT is not None:
                self.timeseries[stn]["th_GEO"], self.timeseries[stn]["az_GEO"] = (
                    dat["th_GEO"],
                    dat["az_GEO"],
                )
                (
                    self.timeseries[stn]["Bx_GEO"],
                    self.timeseries[stn]["By_GEO"],
                    self.timeseries[stn]["Bz_GEO"],
                ) = (dat["B_xyz"][:, 0], dat["B_xyz"][:, 1], dat["B_xyz"][:, 2])
