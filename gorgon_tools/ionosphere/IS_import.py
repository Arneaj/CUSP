"""Module for the ionosphere class."""

import glob
import os
import os.path
import re

import numpy as np
import vtk
from vtk.util.numpy_support import vtk_to_numpy


class ionosphere:
    """Class for importing Gorgon ionosphere data.

    Stores key parameters and imports grid coordinates and variable data from .csv/.vtp
    files generated by the Gorgon MHD code.

    Args:
    ----
        path_to_data (str): Path to directory containing the simulation data
        (same as for gorgon_sim class).
        rad (float, optional): Radius of Earth in metres. Defaults to 6.371e6.
        height (float, optional): Height of ionosphere above Earth's surface in metres.
        Defaults to 100e3.
        IBrad (float, optional): Radius of simulation inner boundary in Earth radii.
        Defaults to 4.
        output (bool, optional): Choose whether to display list of variables and
        timesteps imported. Defaults to False.

    """

    def __init__(
        self, path_to_data, rad=6.371e6, height=110e3, IBrad=4.0, output=False, vtp=True
    ):
        """Initialise ionosphere class."""
        self.tilt = 0  # Will be deprecated in future versions of Gorgon due to use of
        # SM coordinates
        self.r_P = rad  # planetary radius
        self.h_IS = height  # height of ionosphere from surface
        self.r_IS = self.r_P + self.h_IS
        self.r_MS = IBrad * self.r_P
        self.llb = np.pi / 2 - np.arccos(np.sqrt(self.r_IS / self.r_MS))

        self.ftype = "vtp" if vtp else "csv"
        self.fdir = os.sep.join([path_to_data, "IS", os.sep])

        self.arr = {}
        self.arr_cyc = {}  # Cyclical in azimuth, for plotting purposes

        if self.fdir is not None:
            if not vtp:
                files = glob.glob(self.fdir + r"[!th!az]*.csv")
                if len(files) == 0:
                    raise RuntimeError("No files found in directory: " f'"{self.fdir}"')
                file_names = [f.split(os.sep)[-1] for f in files]

                out = np.array([re.split("(?: - )|[.]", f) for f in file_names])

                self.arr_names = np.unique(out[:, 0])
                filename = (
                    self.fdir
                    + self.arr_names[0]
                    + " - "
                    + str(np.min(out[:, 1].astype(int)))
                    + "."
                    + self.ftype
                )
                self.times = np.unique(out[1:, 1:-1])
            else:
                files = glob.glob(self.fdir + r"*.vtp")
                if len(files) == 0:
                    raise RuntimeError("No files found in directory: " f'"{self.fdir}"')
                file_names = [f.split(os.sep)[-1] for f in files]
                out = np.array([re.split("(?:-)|[.]", f) for f in file_names])
                filename = self.fdir + file_names[0]
                self.import_vtp_names(filename)
                self.times = np.unique(out[:, 1:-1])

            s = np.argsort([int(i) for i in self.times])
            self.times = self.times[s].astype(int)
            self.time = self.times[0]
            self.datetime = None

            self.import_space(filename)

            if output:
                print("Ionospheric variables:", self.arr_names)
                print("Timesteps:", self.times)

    def import_space(self, filename):
        """Import the spatial coordinates for the ionospheric grid.

        Imports a test .csv file and reads the shape of the resulting array to determine
        the latitude and longitude values of each grid point.

        Args:
        ----
            filename (str): The path to the file used to import the space information.

        Raises:
        ------
            RuntimeWarning: Fails if no valid files are found.

        """
        # If file not found, exit function
        if not os.path.isfile(filename):
            raise RuntimeWarning("Can't find file: " + filename)
            return

        if self.ftype == "vtp":
            # Create vtk reader
            reader = vtk.vtkXMLPolyDataReader()
            reader.SetFileName(filename)
            reader.Update()
            polydata = reader.GetOutput()
            points = polydata.GetPoints()
            array = points.GetData()
            coords = vtk_to_numpy(array)

            from gorgon_tools.geomagnetic.coordinates import cart_to_sph

            _, th, az = cart_to_sph(coords[:, 0], coords[:, 1], coords[:, 2])
            az = np.where(az < 0, 2 * np.pi + az, az)
            self.th = np.unique(np.round(th * 180 / np.pi, 1)) * np.pi / 180
            self.az = np.unique(np.round(az * 180 / np.pi, 1)) * np.pi / 180
            self.az_cyc = np.append(self.az, 2 * np.pi + self.az[0])
            self.dth = self.th[1:] - self.th[:-1]
            self.daz = self.az[1:] - self.az[:-1]
            self.daz_cyc = self.az_cyc[1:] - self.az_cyc[:-1] % (2 * np.pi)
            # self.daz_cyc[-1] = self.az_cyc[-1]+(2*np.pi)-self.az_cyc[-2]
        else:
            if os.path.isfile(self.fdir + "/th.csv"):
                self.th = (
                    np.genfromtxt(self.fdir + "/th.csv", delimiter=",") * np.pi / 180
                )
                self.az = (
                    np.genfromtxt(self.fdir + "/az.csv", delimiter=",") * np.pi / 180
                )
                self.az_cyc = np.append(self.az, 2 * np.pi + self.az[0])
                self.dth = self.th[1:] - self.th[:-1]
                self.daz = self.az[1:] - self.az[:-1]
                self.daz_cyc = self.az_cyc[1:] - self.az_cyc[:-1](2 * np.pi)
                self.daz_cyc[-1] = self.az_cyc[-1] + (2 * np.pi) - self.az_cyc[-2]
            else:
                dat = np.genfromtxt(filename, delimiter=",")
                daz = 2 * np.pi / len(dat[0, :])
                dth = np.pi / (len(dat[:, 0]) - 1)
                self.az = np.arange(0, 2 * np.pi, daz)
                self.az_cyc = np.append(self.az, 2 * np.pi + self.az[0])
                self.th = np.arange(0, np.pi + dth, dth)
                self.dth = np.zeros([len(self.th) - 1]) + dth
                self.daz = np.zeros([len(self.az)]) + daz
                self.daz_cyc = self.az_cyc[1:] - self.az_cyc[:-1]
            # self.daz_cyc[-1] = self.az_cyc[-1]+(2*np.pi)-self.az_cyc[-2]

    def import_vtp_names(self, filename):
        """Import VTP names from a given file.

        Args:
        ----
            filename (str): The name of the file to import VTP names from.

        Returns:
        -------
            None

        """
        reader = vtk.vtkXMLPolyDataReader()
        reader.SetFileName(filename)
        reader.Update()

        data = reader.GetOutput()
        pointdata = data.GetPointData()
        n_arr = data.GetAttributesAsFieldData(0).GetNumberOfArrays()
        self.arr_names = np.zeros([n_arr]).astype(str)
        for i in range(n_arr):
            arr = pointdata.GetArray(i)
            self.arr_names[i] = arr.GetName()

    def import_timestep(self, t, bad_coords=False):
        """Import ionosphere arrays for a chosen timestep.

        Imports all available .csv files for the specified timestep, and stores a
        periodic (for plotting) and non-periodic (for analysis) instance in separate
        dictionaries.

        Args:
        ----
            t (int): Chosen timestep for which to import variables.
            bad_coords (bool, optional): Choose whether to fix existing issue where
            ionosphere arrays are flipped and/or rotated. Will be deprecated in future.
            Defaults to True.

        """
        self.time = self.times[t]
        self.arr = {}

        if self.ftype == "vtp":
            reader = vtk.vtkXMLPolyDataReader()
            reader.SetFileName(self.fdir + "IS-" + str(self.times[t]) + "." + "vtp")
            reader.Update()

            data = reader.GetOutput()
            pointdata = data.GetPointData()
            for i in range(len(self.arr_names)):
                # Reshape the data into a 2D array
                # 3D if non scalar data (3rd component is component)
                arr = pointdata.GetArray(i)
                if len(vtk_to_numpy(arr).shape) > 1:
                    v = np.reshape(
                        vtk_to_numpy(arr)[1:-1, :], (len(self.th) - 2, len(self.az), 3)
                    )
                    n_pole, s_pole = (
                        0 * v[0, :, :] + [np.mean(v[0, :, :], axis=0)],
                        0 * v[0, :, :] + [np.mean(v[-1, :, :], axis=0)],
                    )
                    n_pole, s_pole = (
                        np.reshape([n_pole], (1, v.shape[1], 3)),
                        np.reshape([s_pole], (1, v.shape[1], 3)),
                    )
                    v = np.append(np.append(n_pole, v, axis=0), s_pole, axis=0)
                else:
                    v = np.reshape(
                        vtk_to_numpy(arr)[1:-1], (len(self.th) - 2, len(self.az))
                    )
                    n_pole, s_pole = (
                        0 * v[0, :] + [np.mean(v[0, :])],
                        0 * v[0, :] + [np.mean(v[-1, :])],
                    )
                    n_pole, s_pole = (
                        np.reshape([n_pole], (v.shape[1], 1)),
                        np.reshape([s_pole], (v.shape[1], 1)),
                    )
                    v = np.append(np.append(n_pole.T, v, axis=0), s_pole.T, axis=0)
                self.arr[arr.GetName()] = v
        else:
            for i in self.arr_names:
                self.arr[i] = np.genfromtxt(
                    self.fdir + i + " - " + str(self.times[t]) + "." + self.ftype,
                    delimiter=",",
                )

            if bad_coords:
                if self.tilt >= 0:
                    self.coordfix_pos()
                else:
                    self.coordfix_neg()

        for i in self.arr_names:
            if len(self.arr[i].shape) == 2:
                az0 = np.reshape([self.arr[i][:, 0]], (self.arr[i].shape[0], 1))
            else:
                az0 = np.reshape([self.arr[i][:, 0, :]], (self.arr[i].shape[0], 1, 3))
            self.arr_cyc[i] = np.append(self.arr[i], az0, axis=1)

    def coordfix_pos(self):
        """Fix a dipole mapping issue in Gorgon.

        Will be deprecated in the future by fixing a dipole mapping issue in Gorgon.

        Fixes an issue whereby imported ionosphere .csv arrays have flipped
        (in colatitude) and rotated (in azimuth) coordinates. This seems to occur for
        dipole tilts of greater than or equal to 0 (i.e. for the GSM north magnetic pole
        being tilted in the sunward direction).

        """
        for i in self.arr_names:
            self.arr[i] = self.arr[i][::-1, ::-1]
            self.arr[i] = np.roll(self.arr[i], len(self.az) // 2 + 1, 1)

    def coordfix_neg(self):
        """Will be deprecated in the future by fixing a dipole mapping issue in Gorgon.

        CARE RECOMMENDED WHEN USING.

        Fixes an issue whereby imported ionosphere .csv arrays have flipped
        (in colatitude) coordinates. This seems to occur for negative dipole tilts
        (i.e. for the GSM north magnetic pole being tilted in the anti-sunward
        direction).

        """
        for i in self.arr_names:
            self.arr[i] = self.arr[i][::-1, ::-1]
            # self.arr[i] = np.roll(self.arr[i],len(self.az)//2+1,1)

    def timestep(self, time):
        """Return the simulation timestep corresponding to a given time.

        Args:
        ----
            time (int): Simulation time in seconds.

        Raises:
        ------
            RuntimeWarning: Fails if there is no data for the given time.

        Returns:
        -------
            int: Timestep corresponding to the given time.

        """
        if not np.any(self.times == time):
            raise RuntimeWarning("Could not import timestep for time: " + str(time))
            return
        else:
            return np.where(self.times == time)[0][0]

    def import_timerange(
        self, starttime=None, endtime=None, t0_UT=None, coords="sim", bad_coords=True
    ):
        """Import data from all timesteps within a given start and end time.

        Data is stored and returned within a dictionary. Optionally transforms data
        to geographic coordinates, if an initial datetime is specified, in which case
        additional geographic coordinate arrays will be stored in the dictionary as well
        as the UT timestamps. Note if no start and end timesteps are specified, the full
        range of timesteps will be imported instead.

        Args:
        ----
            starttime (int, optional): Initial time in seconds. Defaults to None.
            endtime (int, optional): End time in seconds. Defaults to None.
            t0_UT (datetime, optional): UT datetime corresponding to t = 0 in the
            simulation. Defaults to None.
            coords (str, optional): Coordinate system if transformation from 'sim' is
            desired (currently only accepts transformation to 'GEO'). Defaults to 'sim'.
            bad_coords (bool, optional): Choose whether to fix existing issue where
            ionosphere arrays are flipped and/or rotated. Will be deprecated in future.
            Defaults to True.

        Returns:
        -------
            dict: Dictionary containing imported times and arrays.

        """
        # Save currently loaded timestep for later
        t_init = self.timestep(self.time)

        # If no start or end time provided, default to full range
        if starttime is None:
            starttime = self.times[0]
        if endtime is None:
            endtime = self.times[-1]

        # Array of times
        timeseries = {
            "times": np.array(
                self.times[self.timestep(starttime) : self.timestep(endtime) + 1]
            ),
            "th": self.th,
            "az": self.az,
        }

        # Required ionospheric variables
        timeseries["arr_names"] = ["phi", "sig_P", "sig_H", "FAC"]
        for var in timeseries["arr_names"]:
            timeseries[var] = np.zeros(
                [len(self.th), len(self.az), len(timeseries["times"])]
            )

        # Default conductance values if data not available
        if "sig_P" not in self.arr_names:
            timeseries["sig_P"] = timeseries["sig_P"] + 5
        if "sig_H" not in self.arr_names:
            timeseries["sig_H"] = timeseries["sig_H"] + 5

        # Iterate through timesteps and load data
        for t in range(len(timeseries["times"])):
            self.import_timestep(self.timestep(timeseries["times"][t]), bad_coords)
            for var in timeseries["arr_names"]:
                timeseries[var][:, :, t] = self.arr[var]

        # UT datetimes for each time in time range
        import datetime as dt

        if t0_UT is not None:
            timeseries["datetimes"] = [
                t0_UT + dt.timedelta(seconds=int(t)) for t in timeseries["times"]
            ]

        timeseries["coords"] = coords

        # Transform to geographic coordinates
        if coords in ["SM", "GSM", "GSE", "GEI", "GEO", "MAG"]:
            # Initialise separate geographic coordinate arrays
            for var in timeseries["arr_names"]:
                timeseries[var + "_" + coords] = 0 * timeseries[var]

            # Define simulation coordinate system (solar magnetic has flipped X, Y)
            lats_sim, lons_sim = np.meshgrid(np.pi / 2 - self.th, self.az)
            lats_sim, lons_sim = lats_sim.T, lons_sim.T

            from scipy import interpolate

            from ..geomagnetic import coordinates as tform

            # Apply transformations to grid coordinates
            IS_x, IS_y, IS_z = tform.polar_to_cart(
                np.dstack([lats_sim] * len(timeseries["times"])),
                np.dstack([lons_sim] * len(timeseries["times"])),
            )
            IS_x, IS_y, IS_z = -IS_x, -IS_y, IS_z  # sim -> SM
            if coords != "SM":
                IS_x, IS_y, IS_z = tform.GSM_to_SM(
                    IS_x, IS_y, IS_z, timeseries["datetimes"], inv=True
                )  # SM -> GSE
                if coords != "GSM":
                    IS_x, IS_y, IS_z = tform.GSE_to_GSM(
                        IS_x, IS_y, IS_z, timeseries["datetimes"], inv=True
                    )  # GSM-> GSE
                    if coords != "GSE":
                        IS_x, IS_y, IS_z = tform.GEI_to_GSE(
                            IS_x, IS_y, IS_z, timeseries["datetimes"], inv=True
                        )  # GSE -> GEI
                        if coords != "GEI":
                            IS_x, IS_y, IS_z = tform.GEO_to_GEI(
                                IS_x, IS_y, IS_z, timeseries["datetimes"], inv=True
                            )  # GEI -> GEO
            lats, lons = tform.cart_to_polar(IS_x, IS_y, IS_z)
            if coords == "MAG":
                lats, lons = tform.GEO_to_MAG(
                    lats, lons, timeseries["datetimes"]
                )  # GEO -> MAG

            # Interpolate simulated arrays onto geographic coordinates grid
            for var in timeseries["arr_names"]:
                for it in range(len(timeseries["times"])):
                    timeseries[var + "_" + coords][:, :, it] = interpolate.griddata(
                        np.array([lats[:, :, it].ravel(), lons[:, :, it].ravel()]).T,
                        timeseries[var][:, :, it].ravel(),
                        (lats_sim, lons_sim),
                        method="cubic",
                        fill_value=0,
                    )

            # The 0 degree longitude line must unfortunately be padded to 0 by the cubic
            # interpolation
            # Do a linear average of the surrounding longitudes to fill values
            for var in timeseries["arr_names"]:
                timeseries[var][:, 0, :] = 0.5 * (
                    timeseries[var][:, -1, :] + timeseries[var][:, 1, :]
                )
                if coords in ["SM", "GSM", "GSE", "GEI", "GEO", "MAG"]:
                    timeseries[var + "_" + coords][:, 0, :] = 0.5 * (
                        timeseries[var + "_" + coords][:, -1, :]
                        + timeseries[var + "_" + coords][:, 1, :]
                    )

        # Revert to original imported timestep
        self.import_timestep(t_init, bad_coords)

        return timeseries
